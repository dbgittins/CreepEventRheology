{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d783a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import Rheology_fitting_toolkit as rft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aca2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "dictionary_all_events = {}\n",
    "CREEPMETER = ['XHR']\n",
    "\n",
    "for q in range(len(CREEPMETER)):\n",
    "    print(CREEPMETER[q])\n",
    "    tm, min10_creep, tm2, min10_creep2 = rft.import_text(CREEPMETER[q])\n",
    "\n",
    "    if CREEPMETER[q] == 'XSJ' or CREEPMETER[q] == 'XHR' or CREEPMETER[q] == 'XPK':\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "        tm_int2, min10_creep_int2 = rft.interpolate(tm2,min10_creep2,CREEPMETER)\n",
    "    elif CREEPMETER[q] == 'XMR':\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "        tm_int2, min10_creep_int2 = rft.interpolate_1min(tm2,min10_creep2,CREEPMETER)\n",
    "    else:\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "\n",
    "\n",
    "    df_PICKS, duration, START = rft.creepmeter_events(CREEPMETER[q])\n",
    "\n",
    "    if CREEPMETER[q] == 'XSJ' or CREEPMETER[q] == 'XHR' or CREEPMETER[q] == 'XPK':\n",
    "        data1  = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "        data2 = rft.vel_acc(tm_int2,min10_creep_int2,10/60)\n",
    "        data = data1.append(data2,ignore_index=True)\n",
    "    elif CREEPMETER[q] == 'XMR':\n",
    "        data1  = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "        data2 = rft.vel_acc_1min(tm_int2,min10_creep_int2,1/60)\n",
    "        data = data1.append(data2,ignore_index=True)\n",
    "    else:\n",
    "        data = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "\n",
    "\n",
    "    df_auto = rft.parkfield_remover(df_PICKS,CREEPMETER[q])\n",
    "\n",
    "\n",
    "    df_rain_day_total = rft.rain_timeseries(CREEPMETER[q])\n",
    "\n",
    "    df_auto = rft.when_does_it_rain(df_auto,CREEPMETER[q])\n",
    "    \n",
    "    if CREEPMETER[q] == 'CWN':\n",
    "        C_matrix = np.load('../../Rheology/CWN/CWN_covariance_matrix_12days_18_APR_23.npy')\n",
    "        C_matrix_inv_CWN = np.linalg.inv(C_matrix)\n",
    "    \n",
    "    if CREEPMETER[q] == 'XHR':\n",
    "        C_matrix_2 = np.load('../../Rheology/XHR/XHR_2_covariance_matrix_4days_27_APR_23.npy')\n",
    "        C_matrix_3 = np.load('../../Rheology/XHR/XHR_3_covariance_matrix_4days_27_APR_23.npy')\n",
    "        C_matrix_inv_2 = np.linalg.inv(C_matrix_2)\n",
    "        C_matrix_inv_3 = np.linalg.inv(C_matrix_3)\n",
    "    \n",
    "    dataframes_long, creep_index_long = rft.creep_event_dataframe(df_auto,duration, START, data,CREEPMETER[q])\n",
    "    dataframes, creep_index = rft.creep_event_dataframe_short(dataframes_long,df_auto)\n",
    "\n",
    "    Creep_phases = pd.read_csv(\"../../Rheology/{k}/Creep_phases_{k}.csv\".format(k=CREEPMETER[q]),index_col=0)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VSF_aSS_fitter(time,slip,cov_matrix_inv,no_phases,columns_VSF_aSS,j,CREEPMETER,VSF_aSS_DF_params,atest,file_misfit):\n",
    "    \"\"\"\n",
    "    Fit the VSF_aSS rheological model to slip data using basin-hopping optimization.\n",
    "\n",
    "    This function attempts to fit the Velocity Strengthening Friction with aSS (VSF_aSS) \n",
    "    model to the provided slip data for a given event index. It checks if a fit dictionary \n",
    "    file exists for the event; if not, it performs optimization with updated initial \n",
    "    parameters and bounds for the 't1' parameter, repeatedly calling basin-hopping \n",
    "    until a successful fit is found. The fit results and parameters are saved to disk. \n",
    "    If the fit dictionary exists, it loads the stored results.\n",
    "\n",
    "    Args:\n",
    "        time (array-like): Time data points for the event.\n",
    "        slip (array-like): Slip data corresponding to the time points.\n",
    "        cov_matrix_inv (array-like): Inverse covariance matrix for weighting data.\n",
    "        no_phases (int): Number of creep phases in the event.\n",
    "        columns_VSF_aSS (list of str): Column names corresponding to VSF_aSS parameters.\n",
    "        j (int): Event index.\n",
    "        CREEPMETER (str): Identifier for the creepmeter station.\n",
    "        VSF_aSS_DF_params (pandas.DataFrame): DataFrame containing initial guesses and bounds for parameters.\n",
    "        atest (callable): Acceptance test function for basin-hopping.\n",
    "        file_misfit (file-like object): File handle for logging misfit during fitting.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Updated DataFrame with fitted VSF_aSS parameters.\n",
    "    \"\"\"\n",
    "    print('VSF_aSS: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistVSF_aSS = os.path.exists('../../Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/VSF_aSS/{k}_{y}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_t1_neg.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistVSF_aSS:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        VSF_aSS_DF_params['t1'].loc['initial'] = 2\n",
    "        VSF_aSS_DF_params['t1'].loc['bounds'] = (-10,10)\n",
    "        VSF_aSS_bounds = VSF_aSS_DF_params.loc['bounds'].to_list()\n",
    "        VSF_aSS_initial_guess = VSF_aSS_DF_params.loc['initial'].to_list()\n",
    "        \n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_VSF_aSS = scipy.optimize.basinhopping(rft.VSF_aSS_dromedary, VSF_aSS_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_VSF_aSS,j,CREEPMETER,file_misfit),'method':'SLSQP','bounds':VSF_aSS_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_VSF_aSS.success\n",
    "                VSF_aSS_initial_guess = res_VSF_aSS.x\n",
    "        dictionary_VSF_aSS = {}\n",
    "        dictionary_VSF_aSS['fit'] = res_VSF_aSS\n",
    "        VSF_aSS_fitting_params = pd.DataFrame([res_VSF_aSS.x],columns = ('Ts','Vs','K','T01','S1','Ta1','V01','t1','T02','S2'), index = ['fitted'])\n",
    "        VSF_aSS_DF_params = pd.concat([VSF_aSS_DF_params,VSF_aSS_fitting_params])\n",
    "        dictionary_VSF_aSS['fitting params'] = VSF_aSS_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_t1_neg.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_VSF_aSS,tf)\n",
    "\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_t1_neg.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_VSF_aSS = pickle.load(tf)\n",
    "            res_VSF_aSS = dictionary_VSF_aSS['fit']\n",
    "            VSF_aSS_DF_params = dictionary_VSF_aSS['fitting params']\n",
    "    return VSF_aSS_DF_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multi(j):\n",
    "    \"\"\"\n",
    "    Run rheological model fitting and generate fit files and plots for a specific event index.\n",
    "\n",
    "    This function processes slip-time data for the event at index `j` from a collection of\n",
    "    long-duration dataframes. It checks if the processed results and plots already exist\n",
    "    on disk to avoid redundant computations. If not, it performs phase splitting and\n",
    "    initializes parameter bounds for fitting the VSF_aSS rheological model. It then runs\n",
    "    the fitting procedure, saves the results, and prepares directories as needed.\n",
    "\n",
    "    The function focuses on events with up to 577 time points and processes only if the\n",
    "    number of creep phases is 1 or 2. It adjusts parameters and inverse covariance matrix\n",
    "    based on creepmeter and event index.\n",
    "\n",
    "    Args:\n",
    "        j (int): Index of the event in the dataset to process.\n",
    "\n",
    "    Returns:\n",
    "        None: This function operates through side effects (file I/O, printing) and does not return a value.\n",
    "    \"\"\"\n",
    "    print(j)\n",
    "    if len(dataframes_long[j].Time) <= 577:\n",
    "        isExist = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/SLSQP/{y}/{k}_{y}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_t1_neg.pdf'.format(k=CREEPMETER[q],y=j))\n",
    "        if not isExist:\n",
    "            isExist2 = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/{k}_{y}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_t1_neg.txt'.format(k=CREEPMETER[q],y=j))\n",
    "            if not isExist2:\n",
    "                print('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/{k}_{y}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_t1_neg.txt'.format(k=CREEPMETER[q],y=j))\n",
    "                Creep_Phase_no = Creep_phases.iloc[j].dropna()\n",
    "                number_of_phases = (len(Creep_Phase_no)/2)-1\n",
    "                if 1<= number_of_phases <=2:\n",
    "                    data_P0, data_P1, data_P2, data_P3, data_P4, creep_phase_new = rft.phase_splitter(Creep_Phase_no,dataframes_long[j])\n",
    "\n",
    "                    VSF_aSS_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'VSF_aSS')\n",
    "                    if CREEPMETER[q] == 'XHR':\n",
    "                        if j < 70:\n",
    "                            C_matrix_inv = C_matrix_inv_2\n",
    "                        else:\n",
    "                            C_matrix_inv = C_matrix_inv_3\n",
    "                    else:\n",
    "                        C_matrix_inv = C_matrix_inv_CWN\n",
    "\n",
    "                    rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}\".format(k=CREEPMETER[q]))\n",
    "                    Rheologies_to_test = ['LNV','PLV','VSF_SS','VSF_bSS','VSF_aSS','RDF']#,'cb77']\n",
    "                    if number_of_phases==1:\n",
    "                        VSF_aSS_DF_params.drop(['Ta2','V02','t2','T03','S3','Ta3','V03','t3','T04','S4','Ta4','V04','t4'], axis=1, inplace=True)\n",
    "\n",
    "                        for z in range(len(Rheologies_to_test)):\n",
    "                            rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/{x}\".format(k=CREEPMETER[q],u=j,x=Rheologies_to_test[z]))\n",
    "\n",
    "                        VSF_aSS_params_tried = np.zeros(len(VSF_aSS_DF_params.loc['initial'].index.tolist()))\n",
    "                        \n",
    "                        columns_VSF_aSS = VSF_aSS_DF_params.loc['initial'].index.tolist()\n",
    "\n",
    "\n",
    "                        rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}\".format(k=CREEPMETER[q],u=j))\n",
    "\n",
    "                        def atest(f_new, x_new, f_old, x_old):\n",
    "                            if f_old < f_new:\n",
    "                                return False\n",
    "                            else:\n",
    "                                return True\n",
    "\n",
    "                        \n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_t1_neg.txt\".format(k=CREEPMETER[q],u=j),'a') as file_VSF_aSS:\n",
    "                            VSF_aSS_DF_params = VSF_aSS_fitter(np.array(dataframes_long[j].Time),np.array(dataframes_long[j].Slip), C_matrix_inv,number_of_phases,columns_VSF_aSS,j,CREEPMETER[q],\\\n",
    "                                                               VSF_aSS_DF_params,atest,file_VSF_aSS)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0815737",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_all_events = {}\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Use multiprocessing to run `test_multi` on each creep event in `dataframes`.\n",
    "    Currently uses a single worker process (Pool(1)), but can be adjusted for parallelism.\n",
    "    \"\"\"\n",
    "    with Pool(1) as pool:                         # Create a multiprocessing Pool           \n",
    "        pool.map(test_multi, dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VSF_aSS_fitter(time,slip,cov_matrix_inv,no_phases,columns_VSF_aSS,j,CREEPMETER,VSF_aSS_DF_params,atest,file_misfit):\n",
    "    \"\"\"\n",
    "    Fit the VSF_aSS rheological model to slip-time data using basin-hopping optimization.\n",
    "\n",
    "    This function attempts to load a previously saved Nelder-Mead fit result from disk.\n",
    "    If not found, it initializes fitting parameters from a prior SLSQP fit, then performs\n",
    "    a global optimization with the basin-hopping algorithm using Nelder-Mead as the local\n",
    "    minimizer. Results are saved to disk as a pickle file.\n",
    "\n",
    "    Args:\n",
    "        time (np.array): Time data array.\n",
    "        slip (np.array): Slip data array.\n",
    "        cov_matrix_inv (np.array): Inverse covariance matrix used in misfit calculation.\n",
    "        no_phases (int): Number of creep phases to fit.\n",
    "        columns_VSF_aSS (list): List of parameter names for the VSF_aSS model.\n",
    "        j (int): Index of the current event/dataframe being processed.\n",
    "        CREEPMETER (str): Identifier for the creepmeter dataset.\n",
    "        VSF_aSS_DF_params (pd.DataFrame): DataFrame with initial parameters and bounds.\n",
    "        atest (callable): Acceptance test function for basin-hopping.\n",
    "        file_misfit (file-like): File handle for writing misfit information (used in fitting).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame of fitted VSF_aSS parameters.\n",
    "    \"\"\"\n",
    "    print('VSF_aSS: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistVSF_aSS = os.path.exists('../../Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/VSF_aSS/{k}_{y}_VSF_aSS_t1_neg_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistVSF_aSS:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        VSF_aSS_DF_params['t1'].loc['bounds'] = (-10,10)\n",
    "        VSF_aSS_bounds = VSF_aSS_DF_params.loc['bounds'].to_list()\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_t1_neg.txt\".format(k=CREEPMETER,u=j),'rb') as fname:\n",
    "            VSF_aSS_SLSQP = pickle.load(fname)        \n",
    "        VSF_aSS_initial_guess = VSF_aSS_SLSQP['fitting params'].loc['fitted'].to_list() \n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_VSF_aSS = scipy.optimize.basinhopping(rft.VSF_aSS_dromedary, VSF_aSS_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_VSF_aSS,j,CREEPMETER,file_misfit),'method':'Nelder-Mead','bounds':VSF_aSS_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_VSF_aSS.success\n",
    "                VSF_aSS_initial_guess = res_VSF_aSS.x\n",
    "        dictionary_VSF_aSS = {}\n",
    "        dictionary_VSF_aSS['fit'] = res_VSF_aSS\n",
    "        VSF_aSS_fitting_params = pd.DataFrame([res_VSF_aSS.x],columns = ('Ts','Vs','K','T01','S1','Ta1','V01','t1','T02','S2'), index = ['fitted'])\n",
    "        VSF_aSS_DF_params = pd.concat([VSF_aSS_DF_params,VSF_aSS_fitting_params])\n",
    "        dictionary_VSF_aSS['fitting params'] = VSF_aSS_DF_params\n",
    "        #dictionary_VSF_aSS['params tried'] = VSF_aSS_params_tried\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_aSS/{k}_{u}_VSF_aSS_t1_neg_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_VSF_aSS,tf)\n",
    "\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_aSS/{k}_{u}_VSF_aSS_t1_neg_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_VSF_aSS = pickle.load(tf)\n",
    "            res_VSF_aSS = dictionary_VSF_aSS['fit']\n",
    "            VSF_aSS_DF_params = dictionary_VSF_aSS['fitting params']\n",
    "    return VSF_aSS_DF_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_all_events = {}\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Use multiprocessing to run `test_multi` on each creep event in `dataframes`.\n",
    "    Currently uses a single worker process (Pool(1)), but can be adjusted for parallelism.\n",
    "    \"\"\"\n",
    "    with Pool(1) as pool:                         # Create a multiprocessing Pool           \n",
    "        pool.map(test_multi, dataframes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
