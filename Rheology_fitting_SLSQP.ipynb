{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import Rheology_fitting_toolkit as rft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7b078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "dictionary_all_events = {}\n",
    "CREEPMETER = ['XHR']\n",
    "\n",
    "for q in range(len(CREEPMETER)):\n",
    "    print(CREEPMETER[q])\n",
    "    tm, min10_creep, tm2, min10_creep2 = rft.import_text(CREEPMETER[q])\n",
    "\n",
    "    if CREEPMETER[q] == 'XSJ' or CREEPMETER[q] == 'XHR' or CREEPMETER[q] == 'XPK':\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "        tm_int2, min10_creep_int2 = rft.interpolate(tm2,min10_creep2,CREEPMETER)\n",
    "    elif CREEPMETER[q] == 'XMR':\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "        tm_int2, min10_creep_int2 = rft.interpolate_1min(tm2,min10_creep2,CREEPMETER)\n",
    "    else:\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "\n",
    "\n",
    "    df_PICKS, duration, START = rft.creepmeter_events(CREEPMETER[q])\n",
    "\n",
    "    if CREEPMETER[q] == 'XSJ' or CREEPMETER[q] == 'XHR' or CREEPMETER[q] == 'XPK':\n",
    "        data1  = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "        data2 = rft.vel_acc(tm_int2,min10_creep_int2,10/60)\n",
    "        data = data1.append(data2,ignore_index=True)\n",
    "    elif CREEPMETER[q] == 'XMR':\n",
    "        data1  = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "        data2 = rft.vel_acc_1min(tm_int2,min10_creep_int2,1/60)\n",
    "        data = data1.append(data2,ignore_index=True)\n",
    "    else:\n",
    "        data = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "\n",
    "\n",
    "    df_auto = rft.parkfield_remover(df_PICKS,CREEPMETER[q])\n",
    "\n",
    "\n",
    "    df_rain_day_total = rft.rain_timeseries(CREEPMETER[q])\n",
    "\n",
    "    df_auto = rft.when_does_it_rain(df_auto,CREEPMETER[q])\n",
    "    \n",
    "    if CREEPMETER[q] == 'CWN':\n",
    "        C_matrix = np.load('../../Rheology/CWN/CWN_covariance_matrix_12days_18_APR_23.npy')\n",
    "        C_matrix_inv_CWN = np.linalg.inv(C_matrix)\n",
    "    \n",
    "    if CREEPMETER[q] == 'XHR':\n",
    "        C_matrix_2 = np.load('../../Rheology/XHR/XHR_2_covariance_matrix_4days_27_APR_23.npy')\n",
    "        C_matrix_3 = np.load('../../Rheology/XHR/XHR_3_covariance_matrix_4days_27_APR_23.npy')\n",
    "        C_matrix_inv_2 = np.linalg.inv(C_matrix_2)\n",
    "        C_matrix_inv_3 = np.linalg.inv(C_matrix_3)\n",
    "    \n",
    "    \n",
    "    dataframes_long, creep_index_long = rft.creep_event_dataframe(df_auto,duration, START, data,CREEPMETER[q])\n",
    "    dataframes, creep_index = rft.creep_event_dataframe_short(dataframes_long,df_auto)\n",
    "\n",
    "    Creep_phases = pd.read_csv(\"../../Rheology/{k}/Creep_phases_{k}.csv\".format(k=CREEPMETER[q]),index_col=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bacf958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(rft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf60e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LNV_fitter(time,slip,cov_matrix_inv,no_phases,columns_LNV,j,CREEPMETER,LNV_DF_params,atest,file_misfit):\n",
    "    print('Linear Viscous: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    \n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistLNV = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/LNV/{k}_{y}_LNV_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistLNV:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        LNV_bounds = LNV_DF_params.loc['bounds'].to_list()\n",
    "        LNV_initial_guess = LNV_DF_params.loc['initial'].to_list()\n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_LNV = scipy.optimize.basinhopping(rft.LNV_dromedary, LNV_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_LNV,j,CREEPMETER,file_misfit),'method':'SLSQP','bounds':LNV_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)            \n",
    "                n_iter = n_iter+2000\n",
    "                success = res_LNV.success\n",
    "                LNV_initial_guess = res_LNV.x\n",
    "        dictionary_LNV = {}\n",
    "        dictionary_LNV['fit'] = res_LNV\n",
    "        LNV_fitting_params = pd.DataFrame([res_LNV.x],columns = ('Ts','Vs','K','T01','S1','Tau1','V01','T02','S2'), index = ['fitted'])\n",
    "        LNV_DF_params = pd.concat([LNV_DF_params,LNV_fitting_params])\n",
    "        dictionary_LNV['fitting params'] = LNV_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/LNV/{k}_{u}_LNV_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_LNV,tf)\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/LNV/{k}_{u}_LNV_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_LNV = pickle.load(tf)\n",
    "            res_LNV = dictionary_LNV['fit']\n",
    "            LNV_DF_params = dictionary_LNV['fitting params']\n",
    "    return LNV_DF_params\n",
    "\n",
    "###################################################################################################\n",
    "def PLV_fitter(time,slip,cov_matrix_inv,no_phases,columns_PLV,j,CREEPMETER,PLV_DF_params,atest,file_misfit):\n",
    "    print('Power-law Viscous: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistPLV = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/PLV/{k}_{y}_PLV_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistPLV:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        PLV_bounds = PLV_DF_params.loc['bounds'].to_list()\n",
    "        PLV_initial_guess = PLV_DF_params.loc['initial'].to_list()\n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_PLV = scipy.optimize.basinhopping(rft.PLV_dromedary, PLV_initial_guess,\\\n",
    "                accept_test= atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_PLV,j,CREEPMETER,file_misfit),'method':'SLSQP','bounds':PLV_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_PLV.success\n",
    "                PLV_initial_guess = res_PLV.x\n",
    "\n",
    "        dictionary_PLV = {}\n",
    "        dictionary_PLV['fit'] = res_PLV\n",
    "        PLV_fitting_params = pd.DataFrame([res_PLV.x],columns = ('Ts','Vs','K','T01','S1','Tau1','V01','n1','T02','S2'), index = ['fitted'])\n",
    "        PLV_DF_params = pd.concat([PLV_DF_params,PLV_fitting_params])\n",
    "        dictionary_PLV['fitting params'] = PLV_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/PLV/{k}_{u}_PLV_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_PLV,tf)\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/PLV/{k}_{u}_PLV_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_PLV = pickle.load(tf)\n",
    "            res_PLV = dictionary_PLV['fit']\n",
    "            PLV_DF_params = dictionary_PLV['fitting params']\n",
    "    return PLV_DF_params\n",
    "###################################################################################################\n",
    "def VSF_SS_fitter(time,slip,cov_matrix_inv,no_phases,columns_VSF_SS,j,CREEPMETER,VSF_SS_DF_params,atest,file_misfit):\n",
    "    print('VSF-SS: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistVSF_SS = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/VSF_SS/{k}_{y}_VSF_SS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistVSF_SS:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        VSF_SS_bounds = VSF_SS_DF_params.loc['bounds'].to_list()\n",
    "        VSF_SS_initial_guess = VSF_SS_DF_params.loc['initial'].to_list()\n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_VSF_SS = scipy.optimize.basinhopping(rft.VSF_SS_dromedary, VSF_SS_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_VSF_SS,j,CREEPMETER,file_misfit),'method':'SLSQP','bounds':VSF_SS_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_VSF_SS.success\n",
    "                VSF_SS_initial_guess = res_VSF_SS.x\n",
    "\n",
    "        dictionary_VSF_SS = {}\n",
    "        dictionary_VSF_SS['fit'] = res_VSF_SS\n",
    "        VSF_SS_fitting_params = pd.DataFrame([res_VSF_SS.x],columns = ('Ts','Vs','K','T01','S1','Tau1','V01','T02','S2'), index = ['fitted'])\n",
    "        VSF_SS_DF_params = pd.concat([VSF_SS_DF_params,VSF_SS_fitting_params])\n",
    "        dictionary_VSF_SS['fitting params'] = VSF_SS_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_SS/{k}_{u}_VSF_SS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_VSF_SS,tf)\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_SS/{k}_{u}_VSF_SS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_VSF_SS = pickle.load(tf)\n",
    "            res_VSF_SS = dictionary_VSF_SS['fit']\n",
    "            VSF_SS_DF_params = dictionary_VSF_SS['fitting params']\n",
    "    return VSF_SS_DF_params\n",
    "###################################################################################################\n",
    "def VSF_aSS_fitter(time,slip,cov_matrix_inv,no_phases,columns_VSF_aSS,j,CREEPMETER,VSF_aSS_DF_params,atest,file_misfit):\n",
    "    print('VSF_aSS: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistVSF_aSS = os.path.exists('../../Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/VSF_aSS/{k}_{y}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistVSF_aSS:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        VSF_aSS_bounds = VSF_aSS_DF_params.loc['bounds'].to_list()\n",
    "        VSF_aSS_initial_guess = VSF_aSS_DF_params.loc['initial'].to_list()\n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_VSF_aSS = scipy.optimize.basinhopping(rft.VSF_aSS_dromedary, VSF_aSS_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_VSF_aSS,j,CREEPMETER,file_misfit),'method':'SLSQP','bounds':VSF_aSS_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_VSF_aSS.success\n",
    "                VSF_aSS_initial_guess = res_VSF_aSS.x\n",
    "        dictionary_VSF_aSS = {}\n",
    "        dictionary_VSF_aSS['fit'] = res_VSF_aSS\n",
    "        VSF_aSS_fitting_params = pd.DataFrame([res_VSF_aSS.x],columns = ('Ts','Vs','K','T01','S1','Ta1','V01','t1','T02','S2'), index = ['fitted'])\n",
    "        VSF_aSS_DF_params = pd.concat([VSF_aSS_DF_params,VSF_aSS_fitting_params])\n",
    "        dictionary_VSF_aSS['fitting params'] = VSF_aSS_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_VSF_aSS,tf)\n",
    "\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_VSF_aSS = pickle.load(tf)\n",
    "            res_VSF_aSS = dictionary_VSF_aSS['fit']\n",
    "            VSF_aSS_DF_params = dictionary_VSF_aSS['fitting params']\n",
    "    return VSF_aSS_DF_params\n",
    "###################################################################################################\n",
    "def VSF_bSS_fitter(time,slip,cov_matrix_inv,no_phases,columns_VSF_bSS,j,CREEPMETER,VSF_bSS_DF_params,atest,file_misfit):\n",
    "    print('VSF-bSS: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistVSF_bSS = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/VSF_bSS/{k}_{y}_VSF_bSS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistVSF_bSS:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        VSF_bSS_bounds = VSF_bSS_DF_params.loc['bounds'].to_list()\n",
    "        VSF_bSS_initial_guess = VSF_bSS_DF_params.loc['initial'].to_list()\n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_VSF_bSS = scipy.optimize.basinhopping(rft.VSF_bSS_dromedary, VSF_bSS_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_VSF_bSS,j,CREEPMETER,file_misfit),'method':'SLSQP','bounds':VSF_bSS_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_VSF_bSS.success\n",
    "                VSF_bSS_initial_guess = res_VSF_bSS.x\n",
    "\n",
    "        dictionary_VSF_bSS = {}\n",
    "        dictionary_VSF_bSS['fit'] = res_VSF_bSS\n",
    "        VSF_bSS_fitting_params = pd.DataFrame([res_VSF_bSS.x],columns = ('Ts','Vs','K','T01','S1','Tau1','V01','A_B1','T02','S2'), index = ['fitted'])\n",
    "        VSF_bSS_DF_params = pd.concat([VSF_bSS_DF_params,VSF_bSS_fitting_params])\n",
    "        dictionary_VSF_bSS['fitting params'] = VSF_bSS_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_bSS/{k}_{u}_VSF_bSS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_VSF_bSS,tf)\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_bSS/{k}_{u}_VSF_bSS_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_VSF_bSS = pickle.load(tf)\n",
    "            res_VSF_SS = dictionary_VSF_bSS['fit']\n",
    "            VSF_bSS_DF_params = dictionary_VSF_bSS['fitting params']\n",
    "    return VSF_bSS_DF_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36011e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multi(j):\n",
    "    print(j)\n",
    "    if len(dataframes[j].Time) <= 577:\n",
    "        isExist = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/SLSQP/{y}/{k}_{y}_event_plot_Multi_phase_SLSQP_shorter_90_15_MAY_23.pdf'.format(k=CREEPMETER[q],y=j))\n",
    "        if not isExist:\n",
    "            isExist2 = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/{k}_{y}_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt'.format(k=CREEPMETER[q],y=j))\n",
    "            if not isExist2:\n",
    "                print('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{y}/{k}_{y}_fit_dictionary_multi_phase_SLSQP_shorter_90_15_MAY_23.txt'.format(k=CREEPMETER[q],y=j))\n",
    "                Creep_Phase_no = Creep_phases.iloc[j].dropna()\n",
    "                number_of_phases = (len(Creep_Phase_no)/2)-1\n",
    "                if 1<= number_of_phases <=2:\n",
    "                    data_P0, data_P1, data_P2, data_P3, data_P4, creep_phase_new = rft.phase_splitter(Creep_Phase_no,dataframes[j])\n",
    "\n",
    "                    LNV_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'LNV')\n",
    "                    PLV_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'PLV')\n",
    "                    VSF_SS_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'VSF_SS')\n",
    "                    VSF_bSS_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'VSF_bSS')\n",
    "                    VSF_aSS_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'VSF_aSS')\n",
    "\n",
    "                    if CREEPMETER[q] == 'XHR':\n",
    "                        if j < 70:\n",
    "                            C_matrix_inv = C_matrix_inv_2\n",
    "                        else:\n",
    "                            C_matrix_inv = C_matrix_inv_3\n",
    "                    else:\n",
    "                        C_matrix_inv = C_matrix_inv_CWN\n",
    "\n",
    "                    rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}\".format(k=CREEPMETER[q]))\n",
    "                    Rheologies_to_test = ['LNV','PLV','VSF_SS','VSF_bSS','VSF_aSS']\n",
    "                    if number_of_phases==1:\n",
    "                        LNV_DF_params.drop(['Tau2','V02','T03','S3','Tau3','V03','T04','S4','Tau4','V04'], axis=1, inplace=True)\n",
    "                        PLV_DF_params.drop(['Tau2','V02','n2','T03','S3','Tau3','V03','n3','T04','S4','Tau4','V04','n4'], axis=1, inplace=True)\n",
    "                        VSF_SS_DF_params.drop(['Tau2','V02','T03','S3','Tau3','V03','T04','S4','Tau4','V04'], axis=1, inplace=True)\n",
    "                        VSF_bSS_DF_params.drop(['Tau2','V02','A_B2','T03','S3','Tau3','V03','A_B3','T04','S4','Tau4','V04','A_B4'], axis=1, inplace=True)\n",
    "                        VSF_aSS_DF_params.drop(['Ta2','V02','t2','T03','S3','Ta3','V03','t3','T04','S4','Ta4','V04','t4'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "                        for z in range(len(Rheologies_to_test)):\n",
    "                            rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/{x}\".format(k=CREEPMETER[q],u=j,x=Rheologies_to_test[z]))\n",
    "\n",
    "                        LNV_params_tried = np.zeros(len(LNV_DF_params.loc['initial'].index.tolist()))\n",
    "                        PLV_params_tried = np.zeros(len(PLV_DF_params.loc['initial'].index.tolist()))\n",
    "                        VSF_SS_params_tried = np.zeros(len(VSF_SS_DF_params.loc['initial'].index.tolist()))\n",
    "                        VSF_bSS_params_tried = np.zeros(len(VSF_bSS_DF_params.loc['initial'].index.tolist()))\n",
    "                        VSF_aSS_params_tried = np.zeros(len(VSF_aSS_DF_params.loc['initial'].index.tolist()))\n",
    "\n",
    "                        columns_LNV = LNV_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_PLV = PLV_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_VSF_SS = VSF_SS_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_VSF_bSS = VSF_bSS_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_VSF_aSS = VSF_aSS_DF_params.loc['initial'].index.tolist()\n",
    "\n",
    "                        rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}\".format(k=CREEPMETER[q],u=j))\n",
    "\n",
    "                        def atest(f_new, x_new, f_old, x_old):\n",
    "                            if f_old < f_new:\n",
    "                                return False\n",
    "                            else:\n",
    "                                return True\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/LNV/{k}_{u}_LNV_misfit_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_LNV:\n",
    "                            LNV_DF_params = LNV_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_LNV,j,CREEPMETER[q],LNV_DF_params,atest,file_LNV)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/PLV/{k}_{u}_PLV_misfit_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_PLV:\n",
    "                            PLV_DF_params = PLV_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_PLV,j,CREEPMETER[q],PLV_DF_params,atest,file_PLV)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_SS/{k}_{u}_VSF_SS_misfit_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_VSF_SS:\n",
    "                            VSF_SS_DF_params = VSF_SS_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_VSF_SS,j,CREEPMETER[q],\\\n",
    "                                                             VSF_SS_DF_params,atest,file_VSF_SS)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_bSS/{k}_{u}_VSF_bSS_misfit_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_VSF_bSS:\n",
    "                            VSF_bSS_DF_params = VSF_bSS_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_VSF_bSS,j,CREEPMETER[q],\\\n",
    "                                                               VSF_bSS_DF_params,atest,file_VSF_bSS)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_aSS/{k}_{u}_VSF_aSS_misfit_SLSQP_shorter_90_15_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_VSF_aSS:\n",
    "                            VSF_aSS_DF_params = VSF_aSS_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_VSF_aSS,j,CREEPMETER[q],\\\n",
    "                                                               VSF_aSS_DF_params,atest,file_VSF_aSS)\n",
    "\n",
    "                           \n",
    "                        test_t = np.arange(0,max(dataframes[j].Time.iloc[1:]),0.01)\n",
    "                        rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/SLSQP\".format(k=CREEPMETER[q]))\n",
    "                        \n",
    "                        slip_LNV = rft.LNV_dromedary_plot(LNV_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_PLV = rft.PLV_dromedary_plot(PLV_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_VSF = rft.VSF_dromedary_plot(VSF_SS_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_VSF_bSS = rft.VSF_bSS_dromedary_plot(VSF_bSS_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_VSF_aSS = rft.VSF_aSS_dromedary_plot(VSF_aSS_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        #slip_cb77 = rft.CB77_dromedary_plot(cb77_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "\n",
    "                        colors = ['#74add1','#313695','#a50026','#d73027','#f46d43','#fdae61']\n",
    "\n",
    "                        print('saving figure {k}'.format(k=j))        \n",
    "                        plt.figure()\n",
    "                        plt.scatter(dataframes[j].Time-2,dataframes[j].Slip, label='Observed Data',s=5,color='#000000', zorder=100)   \n",
    "                        plt.plot(test_t-2,slip_LNV,label = 'Linear Viscous Flow', color = colors[0], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_PLV,label='Power-law Viscous Flow', color = colors[1], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_VSF,label = 'Velocity Strengthening Friction\\n - steady state', color = colors[2], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_VSF_aSS,label = 'R+S - Stress >> Steady State', color = colors[3], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_VSF_bSS,label = 'R+S - Stress << Steady State', color = colors[4], linewidth=2, linestyle = '-')\n",
    "                        plt.legend(fontsize=11)\n",
    "                        plt.xlabel('Time since start of event, hrs', fontsize=14)\n",
    "                        plt.ylabel('Slip, mm',fontsize=14)\n",
    "                        plt.xticks(fontsize=14)\n",
    "                        plt.yticks(fontsize=14)\n",
    "                        plt.title('{K}_{P}'.format(K = CREEPMETER[q], P = j ),fontsize=18)\n",
    "                        figure = plt.gcf()  # get current figure\n",
    "                        figure.set_size_inches(6,6)\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/SLSQP/{k}_{u}_event_plot_Multi_phase_SLSQP_shorter_90_15_MAY_23.pdf\".format(k=CREEPMETER[q],u=j),format='pdf')\n",
    "                        plt.savefig(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/SLSQP/{k}_{u}_event_plot_Multi_phase_SLSQP_shorter_90_15_MAY_23.png\".format(k=CREEPMETER[q],u=j),format='pdf')\n",
    "                        plt.close('all')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_all_events = {}\n",
    "if __name__ == '__main__':\n",
    "    with Pool(1) as pool:                         # Create a multiprocessing Pool           \n",
    "        pool.map(test_multi, dataframes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
