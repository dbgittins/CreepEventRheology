{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_242063/4207224591.py:16: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.backends.backend_pdf\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import pickle\n",
    "import matplotlib.colors as Colors\n",
    "from numba import jit\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import Rheology_fitting_toolkit as rft\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import creep_part_identify as cpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7b078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XHR\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "dictionary_all_events = {}\n",
    "CREEPMETER = ['XHR']\n",
    "for q in range(len(CREEPMETER)):\n",
    "    print(CREEPMETER[q])\n",
    "    tm, min10_creep, tm2, min10_creep2 = rft.import_text(CREEPMETER[q])\n",
    "\n",
    "    if CREEPMETER[q] == 'XSJ' or CREEPMETER[q] == 'XHR' or CREEPMETER[q] == 'XPK':\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "        tm_int2, min10_creep_int2 = rft.interpolate(tm2,min10_creep2,CREEPMETER)\n",
    "    elif CREEPMETER[q] == 'XMR':\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "        tm_int2, min10_creep_int2 = rft.interpolate_1min(tm2,min10_creep2,CREEPMETER)\n",
    "    else:\n",
    "        tm_int, min10_creep_int = rft.interpolate(tm,min10_creep,CREEPMETER)\n",
    "\n",
    "\n",
    "    df_PICKS, duration, START = rft.creepmeter_events(CREEPMETER[q])\n",
    "\n",
    "    if CREEPMETER[q] == 'XSJ' or CREEPMETER[q] == 'XHR' or CREEPMETER[q] == 'XPK':\n",
    "        data1  = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "        data2 = rft.vel_acc(tm_int2,min10_creep_int2,10/60)\n",
    "        data = data1.append(data2,ignore_index=True)\n",
    "    elif CREEPMETER[q] == 'XMR':\n",
    "        data1  = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "        data2 = rft.vel_acc_1min(tm_int2,min10_creep_int2,1/60)\n",
    "        data = data1.append(data2,ignore_index=True)\n",
    "    else:\n",
    "        data = rft.vel_acc(tm_int,min10_creep_int,10/60)\n",
    "\n",
    "\n",
    "    df_auto = rft.parkfield_remover(df_PICKS,CREEPMETER[q])\n",
    "\n",
    "\n",
    "    df_rain_day_total = rft.rain_timeseries(CREEPMETER[q])\n",
    "\n",
    "    df_auto = rft.when_does_it_rain(df_auto,CREEPMETER[q])\n",
    "    \n",
    "    if CREEPMETER[q] == 'CWN':\n",
    "        C_matrix = np.load('../../Rheology/CWN/CWN_covariance_matrix_12days_18_APR_23.npy')\n",
    "        C_matrix_inv_CWN = np.linalg.inv(C_matrix)\n",
    "    \n",
    "    if CREEPMETER[q] == 'XHR':\n",
    "        C_matrix_2 = np.load('../../Rheology/XHR/XHR_2_covariance_matrix_4days_27_APR_23.npy')\n",
    "        C_matrix_3 = np.load('../../Rheology/XHR/XHR_3_covariance_matrix_4days_27_APR_23.npy')\n",
    "        C_matrix_inv_2 = np.linalg.inv(C_matrix_2)\n",
    "        C_matrix_inv_3 = np.linalg.inv(C_matrix_3)\n",
    "\n",
    "    \n",
    "    dataframes, creep_index = rft.creep_event_dataframe(df_auto,duration, START, data,CREEPMETER[q])\n",
    "\n",
    "    Creep_phases = pd.read_csv(\"../../Rheology/{k}/Creep_phases_{k}.csv\".format(k=CREEPMETER[q]),index_col=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bacf958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Rheology_fitting_toolkit' from '/home/users/exet4136/CREEPMETER_DATA/SCRIPTS/Onset/Rheology_fitting_toolkit.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(rft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf60e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LNV_fitter(time,slip,cov_matrix_inv,no_phases,columns_LNV,j,CREEPMETER,LNV_DF_params,atest,file_misfit):\n",
    "    print('Linear Viscous: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    isExistLNV = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/LNV/{k}_{y}_LNV_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    if not isExistLNV:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        LNV_bounds = LNV_DF_params.loc['bounds'].to_list()\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/LNV/{k}_{u}_LNV_fit_dictionary_multi_phase_SLSQP_28_APR_23.txt\".format(k=CREEPMETER,u=j),'rb') as fname:\n",
    "            LNV_SLSQP = pickle.load(fname)\n",
    "        LNV_initial_guess = LNV_SLSQP['fitting params'].loc['fitted'].to_list()\n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_LNV = scipy.optimize.basinhopping(rft.LNV_dromedary, LNV_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_LNV,j,CREEPMETER,file_misfit),'method':'Nelder-Mead','bounds':LNV_bounds,'options':{'maxiter':n_iter}}),niter=1000)            \n",
    "                n_iter = n_iter+2000\n",
    "                success = res_LNV.success\n",
    "                LNV_initial_guess = res_LNV.x\n",
    "        dictionary_LNV = {}\n",
    "        dictionary_LNV['fit'] = res_LNV\n",
    "        LNV_fitting_params = pd.DataFrame([res_LNV.x],columns = ('Ts','Vs','K','T01','S1','Tau1','V01','T02','S2'), index = ['fitted'])\n",
    "        LNV_DF_params = pd.concat([LNV_DF_params,LNV_fitting_params])\n",
    "        dictionary_LNV['fitting params'] = LNV_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/LNV/{k}_{u}_LNV_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_LNV,tf)\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/LNV/{k}_{u}_LNV_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_LNV = pickle.load(tf)\n",
    "            res_LNV = dictionary_LNV['fit']\n",
    "            LNV_DF_params = dictionary_LNV['fitting params']\n",
    "    return LNV_DF_params\n",
    "\n",
    "###################################################################################################\n",
    "def PLV_fitter(time,slip,cov_matrix_inv,no_phases,columns_PLV,j,CREEPMETER,PLV_DF_params,atest,file_misfit):\n",
    "    print('Power-law Viscous: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistPLV = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/PLV/{k}_{y}_PLV_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistPLV:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        PLV_bounds = PLV_DF_params.loc['bounds'].to_list()\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/PLV/{k}_{u}_PLV_fit_dictionary_multi_phase_SLSQP_28_APR_23.txt\".format(k=CREEPMETER,u=j),'rb') as fname:\n",
    "            PLV_SLSQP = pickle.load(fname)\n",
    "        PLV_initial_guess = PLV_SLSQP['fitting params'].loc['fitted'].to_list()\n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_PLV = scipy.optimize.basinhopping(rft.PLV_dromedary, PLV_initial_guess,\\\n",
    "                accept_test= atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_PLV,j,CREEPMETER,file_misfit),'method':'Nelder-Mead','bounds':PLV_bounds,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_PLV.success\n",
    "                PLV_initial_guess = res_PLV.x\n",
    "\n",
    "        dictionary_PLV = {}\n",
    "        dictionary_PLV['fit'] = res_PLV\n",
    "        PLV_fitting_params = pd.DataFrame([res_PLV.x],columns = ('Ts','Vs','K','T01','S1','Tau1','V01','n1','T02','S2'), index = ['fitted'])\n",
    "        PLV_DF_params = pd.concat([PLV_DF_params,PLV_fitting_params])\n",
    "        dictionary_PLV['fitting params'] = PLV_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/PLV/{k}_{u}_PLV_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_PLV,tf)\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/PLV/{k}_{u}_PLV_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_PLV = pickle.load(tf)\n",
    "            res_PLV = dictionary_PLV['fit']\n",
    "            PLV_DF_params = dictionary_PLV['fitting params']\n",
    "    return PLV_DF_params\n",
    "###################################################################################################\n",
    "def VSF_SS_fitter(time,slip,cov_matrix_inv,no_phases,columns_VSF_SS,j,CREEPMETER,VSF_SS_DF_params,atest,file_misfit):\n",
    "    print('VSF-SS: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistVSF_SS = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/VSF_SS/{k}_{y}_VSF_SS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistVSF_SS:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        VSF_SS_bounds = VSF_SS_DF_params.loc['bounds'].to_list()\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_SS/{k}_{u}_VSF_SS_fit_dictionary_multi_phase_SLSQP_28_APR_23.txt\".format(k=CREEPMETER,u=j),'rb') as fname:\n",
    "            VSF_SS_SLSQP = pickle.load(fname)\n",
    "        VSF_SS_initial_guess = VSF_SS_SLSQP['fitting params'].loc['fitted'].to_list()        \n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_VSF_SS = scipy.optimize.basinhopping(rft.VSF_SS_dromedary, VSF_SS_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_VSF_SS,j,CREEPMETER,file_misfit),'method':'Nelder-Mead','bounds':VSF_SS_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_VSF_SS.success\n",
    "                VSF_SS_initial_guess = res_VSF_SS.x\n",
    "\n",
    "        dictionary_VSF_SS = {}\n",
    "        dictionary_VSF_SS['fit'] = res_VSF_SS\n",
    "        VSF_SS_fitting_params = pd.DataFrame([res_VSF_SS.x],columns = ('Ts','Vs','K','T01','S1','Tau1','V01','T02','S2'), index = ['fitted'])\n",
    "        VSF_SS_DF_params = pd.concat([VSF_SS_DF_params,VSF_SS_fitting_params])\n",
    "        dictionary_VSF_SS['fitting params'] = VSF_SS_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_SS/{k}_{u}_VSF_SS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_VSF_SS,tf)\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_SS/{k}_{u}_VSF_SS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_VSF_SS = pickle.load(tf)\n",
    "            res_VSF_SS = dictionary_VSF_SS['fit']\n",
    "            VSF_SS_DF_params = dictionary_VSF_SS['fitting params']\n",
    "    return VSF_SS_DF_params\n",
    "###################################################################################################\n",
    "def RDF_fitter(time,slip,cov_matrix_inv,no_phases,columns_RDF,j,CREEPMETER,RDF_DF_params,atest,file_misfit):\n",
    "    print('RDF: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistRDF = os.path.exists('../../Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/RDF/{k}_{y}_RDF_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistRDF:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        RDF_bounds = RDF_DF_params.loc['bounds'].to_list()\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/RDF/{k}_{u}_RDF_SS_fit_dictionary_multi_phase_SLSQP_28_APR_23.txt\".format(k=CREEPMETER,u=j),'rb') as fname:\n",
    "            RDF_SLSQP = pickle.load(fname)\n",
    "        RDF_initial_guess = RDF_SLSQP['fitting params'].loc['fitted'].to_list() \n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_RDF = scipy.optimize.basinhopping(rft.RDF_dromedary, RDF_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_RDF,j,CREEPMETER,file_misfit),'method':'Nelder-Mead','bounds':RDF_bounds,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_RDF.success\n",
    "                RDF_initial_guess = res_RDF.x\n",
    "        dictionary_RDF = {}\n",
    "        dictionary_RDF['fit'] = res_RDF\n",
    "        RDF_fitting_params = pd.DataFrame([res_RDF.x],columns = ('Ts','Vs','K','T01','S1','Ta1','V01','V0/VL1','T02','S2'), index = ['fitted'])\n",
    "        RDF_DF_params = pd.concat([RDF_DF_params,RDF_fitting_params])\n",
    "        dictionary_RDF['fitting params'] = RDF_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/RDF/{k}_{u}_RDF_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_RDF,tf)\n",
    "\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/RDF/{k}_{u}_RDF_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_RDF = pickle.load(tf)\n",
    "            res_RDF = dictionary_RDF['fit']\n",
    "            RDF_DF_params = dictionary_RDF['fitting params']\n",
    "    return RDF_DF_params\n",
    "###################################################################################################\n",
    "def VSF_aSS_fitter(time,slip,cov_matrix_inv,no_phases,columns_VSF_aSS,j,CREEPMETER,VSF_aSS_DF_params,atest,file_misfit):\n",
    "    print('VSF_aSS: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistVSF_aSS = os.path.exists('../../Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/VSF_aSS/{k}_{y}_VSF_aSS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistVSF_aSS:\n",
    "        #print('../../Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/VSF_aSS/{k}_{y}_VSF_aSS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER[q],y=j))\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        VSF_aSS_bounds = VSF_aSS_DF_params.loc['bounds'].to_list()\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_SLSQP_28_APR_23.txt\".format(k=CREEPMETER,u=j),'rb') as fname:\n",
    "            VSF_aSS_SLSQP = pickle.load(fname)        \n",
    "        VSF_aSS_initial_guess = VSF_aSS_SLSQP['fitting params'].loc['fitted'].to_list() \n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_VSF_aSS = scipy.optimize.basinhopping(rft.VSF_aSS_dromedary, VSF_aSS_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_VSF_aSS,j,CREEPMETER,file_misfit),'method':'Nelder-Mead','bounds':VSF_aSS_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_VSF_aSS.success\n",
    "                VSF_aSS_initial_guess = res_VSF_aSS.x\n",
    "        dictionary_VSF_aSS = {}\n",
    "        dictionary_VSF_aSS['fit'] = res_VSF_aSS\n",
    "        VSF_aSS_fitting_params = pd.DataFrame([res_VSF_aSS.x],columns = ('Ts','Vs','K','T01','S1','Ta1','V01','t1','T02','S2'), index = ['fitted'])\n",
    "        VSF_aSS_DF_params = pd.concat([VSF_aSS_DF_params,VSF_aSS_fitting_params])\n",
    "        dictionary_VSF_aSS['fitting params'] = VSF_aSS_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_VSF_aSS,tf)\n",
    "\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_aSS/{k}_{u}_VSF_aSS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_VSF_aSS = pickle.load(tf)\n",
    "            res_VSF_aSS = dictionary_VSF_aSS['fit']\n",
    "            VSF_aSS_DF_params = dictionary_VSF_aSS['fitting params']\n",
    "    return VSF_aSS_DF_params\n",
    "###################################################################################################\n",
    "def VSF_bSS_fitter(time,slip,cov_matrix_inv,no_phases,columns_VSF_bSS,j,CREEPMETER,VSF_bSS_DF_params,atest,file_misfit):\n",
    "    print('VSF-bSS: {k}'.format(k=j))\n",
    "    print (\"Current date and time : \")\n",
    "    print (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    isExistVSF_bSS = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/VSF_bSS/{k}_{y}_VSF_bSS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER,y=j))\n",
    "    if not isExistVSF_bSS:\n",
    "        success = False\n",
    "        n_iter = 5000\n",
    "        VSF_bSS_bounds = VSF_bSS_DF_params.loc['bounds'].to_list()\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/SLSQP/{u}/VSF_bSS/{k}_{u}_VSF_bSS_fit_dictionary_multi_phase_SLSQP_28_APR_23.txt\".format(k=CREEPMETER,u=j),'rb') as fname:\n",
    "            VSF_bSS_SLSQP = pickle.load(fname)\n",
    "        VSF_bSS_initial_guess = VSF_bSS_SLSQP['fitting params'].loc['fitted'].to_list() \n",
    "        while success == False:\n",
    "            if success == False:\n",
    "                res_VSF_bSS = scipy.optimize.basinhopping(rft.VSF_bSS_dromedary, VSF_bSS_initial_guess,\\\n",
    "                accept_test = atest, minimizer_kwargs = ({'args':(time,slip,cov_matrix_inv,no_phases,\\\n",
    "                columns_VSF_bSS,j,CREEPMETER,file_misfit),'method':'Nelder-Mead','bounds':VSF_bSS_bounds}))#,'options':{'maxiter':n_iter}}),niter=1000)\n",
    "                n_iter = n_iter+2000\n",
    "                success = res_VSF_bSS.success\n",
    "                VSF_bSS_initial_guess = res_VSF_bSS.x\n",
    "\n",
    "        dictionary_VSF_bSS = {}\n",
    "        dictionary_VSF_bSS['fit'] = res_VSF_bSS\n",
    "        VSF_bSS_fitting_params = pd.DataFrame([res_VSF_bSS.x],columns = ('Ts','Vs','K','T01','S1','Tau1','V01','A_B1','T02','S2'), index = ['fitted'])\n",
    "        VSF_bSS_DF_params = pd.concat([VSF_bSS_DF_params,VSF_bSS_fitting_params])\n",
    "        dictionary_VSF_bSS['fitting params'] = VSF_bSS_DF_params\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_bSS/{k}_{u}_VSF_bSS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"wb\") as tf:\n",
    "            pickle.dump(dictionary_VSF_bSS,tf)\n",
    "    else:\n",
    "        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_bSS/{k}_{u}_VSF_bSS_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER,u=j), \"rb\") as tf:\n",
    "            dictionary_VSF_bSS = pickle.load(tf)\n",
    "            res_VSF_SS = dictionary_VSF_bSS['fit']\n",
    "            VSF_bSS_DF_params = dictionary_VSF_bSS['fitting params']\n",
    "    return VSF_bSS_DF_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36011e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multi(j):\n",
    "    print(j)\n",
    "    if len(dataframes[j].Time) <= 577:\n",
    "        isExist = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/Nelder-Mead/{y}/{k}_{y}_event_plot_Multi_phase_Nelder-Mead_01_MAY_23.pdf'.format(k=CREEPMETER[q],y=j))\n",
    "        if not isExist:\n",
    "            isExist2 = os.path.exists('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/{k}_{y}_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER[q],y=j))\n",
    "            if not isExist2:\n",
    "                print('/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{y}/{k}_{y}_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt'.format(k=CREEPMETER[q],y=j))\n",
    "                Creep_Phase_no = Creep_phases.iloc[j].dropna()\n",
    "                number_of_phases = (len(Creep_Phase_no)/2)-1\n",
    "                if 1<= number_of_phases <=2:\n",
    "                    data_P0, data_P1, data_P2, data_P3, data_P4, creep_phase_new = rft.phase_splitter(Creep_Phase_no,dataframes[j])\n",
    "\n",
    "                    LNV_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'LNV')\n",
    "                    PLV_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'PLV')\n",
    "                    VSF_SS_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'VSF_SS')\n",
    "                    VSF_bSS_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'VSF_bSS')\n",
    "                    VSF_aSS_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'VSF_aSS')\n",
    "                    RDF_DF_params = rft.initial_and_bounds(creep_phase_new,data_P0,data_P1,data_P2,data_P3,data_P4,'RDF')\n",
    "\n",
    "                    if CREEPMETER[q] == 'XHR':\n",
    "                        if j < 70:\n",
    "                            C_matrix_inv = C_matrix_inv_2\n",
    "                        else:\n",
    "                            C_matrix_inv = C_matrix_inv_3\n",
    "                    else:\n",
    "                        C_matrix_inv = C_matrix_inv_CWN\n",
    "\n",
    "                    rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}\".format(k=CREEPMETER[q]))\n",
    "                    Rheologies_to_test = ['LNV','PLV','VSF_SS','VSF_bSS','VSF_aSS','RDF']#,'cb77']\n",
    "                    if number_of_phases==1:\n",
    "                        LNV_DF_params.drop(['Tau2','V02','T03','S3','Tau3','V03','T04','S4','Tau4','V04'], axis=1, inplace=True)\n",
    "                        PLV_DF_params.drop(['Tau2','V02','n2','T03','S3','Tau3','V03','n3','T04','S4','Tau4','V04','n4'], axis=1, inplace=True)\n",
    "                        VSF_SS_DF_params.drop(['Tau2','V02','T03','S3','Tau3','V03','T04','S4','Tau4','V04'], axis=1, inplace=True)\n",
    "                        VSF_bSS_DF_params.drop(['Tau2','V02','A_B2','T03','S3','Tau3','V03','A_B3','T04','S4','Tau4','V04','A_B4'], axis=1, inplace=True)\n",
    "                        VSF_aSS_DF_params.drop(['Ta2','V02','t2','T03','S3','Ta3','V03','t3','T04','S4','Ta4','V04','t4'], axis=1, inplace=True)\n",
    "                        RDF_DF_params.drop(['Ta2','V02','V0/VL2','T03','S3','Ta3','V03','V0/VL3','T04','S4','Ta4','V04','V0/VL4'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "                        for z in range(len(Rheologies_to_test)):\n",
    "                            rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/{x}\".format(k=CREEPMETER[q],u=j,x=Rheologies_to_test[z]))\n",
    "\n",
    "                        LNV_params_tried = np.zeros(len(LNV_DF_params.loc['initial'].index.tolist()))\n",
    "                        PLV_params_tried = np.zeros(len(PLV_DF_params.loc['initial'].index.tolist()))\n",
    "                        VSF_SS_params_tried = np.zeros(len(VSF_SS_DF_params.loc['initial'].index.tolist()))\n",
    "                        VSF_bSS_params_tried = np.zeros(len(VSF_bSS_DF_params.loc['initial'].index.tolist()))\n",
    "                        VSF_aSS_params_tried = np.zeros(len(VSF_aSS_DF_params.loc['initial'].index.tolist()))\n",
    "                        RDF_params_tried = np.zeros(len(RDF_DF_params.loc['initial'].index.tolist()))\n",
    "\n",
    "                        columns_LNV = LNV_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_PLV = PLV_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_VSF_SS = VSF_SS_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_VSF_bSS = VSF_bSS_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_VSF_aSS = VSF_aSS_DF_params.loc['initial'].index.tolist()\n",
    "                        columns_RDF = RDF_DF_params.loc['initial'].index.tolist()\n",
    "\n",
    "                        rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}\".format(k=CREEPMETER[q],u=j))\n",
    "\n",
    "                        def atest(f_new, x_new, f_old, x_old):\n",
    "                            if f_old < f_new:\n",
    "                                return False\n",
    "                            else:\n",
    "                                return True\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/LNV/{k}_{u}_LNV_misfit_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_LNV:\n",
    "                            LNV_DF_params = LNV_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_LNV,j,CREEPMETER[q],LNV_DF_params,atest,file_LNV)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/PLV/{k}_{u}_PLV_misfit_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_PLV:\n",
    "                            PLV_DF_params = PLV_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_PLV,j,CREEPMETER[q],PLV_DF_params,atest,file_PLV)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_SS/{k}_{u}_VSF_SS_misfit_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_VSF_SS:\n",
    "                            VSF_SS_DF_params = VSF_SS_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_VSF_SS,j,CREEPMETER[q],\\\n",
    "                                                             VSF_SS_DF_params,atest,file_VSF_SS)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_bSS/{k}_{u}_VSF_bSS_misfit_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_VSF_bSS:\n",
    "                            VSF_bSS_DF_params = VSF_bSS_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_VSF_bSS,j,CREEPMETER[q],\\\n",
    "                                                               VSF_bSS_DF_params,atest,file_VSF_bSS)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/VSF_aSS/{k}_{u}_VSF_aSS_misfit_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_VSF_aSS:\n",
    "                            VSF_aSS_DF_params = VSF_aSS_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_VSF_aSS,j,CREEPMETER[q],\\\n",
    "                                                               VSF_aSS_DF_params,atest,file_VSF_aSS)\n",
    "\n",
    "                        with open(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/fits/Nelder-Mead/{u}/RDF/{k}_{u}_RDF_misfit_Nelder-Mead_01_MAY_23.txt\".format(k=CREEPMETER[q],u=j),'a') as file_RDF:\n",
    "                            RDF_DF_params = RDF_fitter(np.array(dataframes[j].Time),np.array(dataframes[j].Slip), C_matrix_inv,number_of_phases,columns_RDF,j,CREEPMETER[q],RDF_DF_params,atest,file_RDF)\n",
    "                        \n",
    "                        test_t = np.arange(0,max(dataframes[j].Time.iloc[1:]),0.01)\n",
    "                        rft.check_dir(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/Nelder-Mead\".format(k=CREEPMETER[q]))\n",
    "                        \n",
    "                        slip_LNV = rft.LNV_dromedary_plot(LNV_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_PLV = rft.PLV_dromedary_plot(PLV_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_VSF = rft.VSF_dromedary_plot(VSF_SS_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_VSF_bSS = rft.VSF_bSS_dromedary_plot(VSF_bSS_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_VSF_aSS = rft.VSF_aSS_dromedary_plot(VSF_aSS_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "                        slip_RDF = rft.RDF_dromedary_plot(RDF_DF_params.loc['fitted'],test_t,number_of_phases)\n",
    "\n",
    "                        colors = ['#74add1','#313695','#a50026','#d73027','#f46d43','#fdae61']\n",
    "\n",
    "                        print('saving figure {k}'.format(k=j))        \n",
    "                        plt.figure()\n",
    "                        plt.scatter(dataframes[j].Time-2,dataframes[j].Slip, label='Observed Data',s=5,color='#000000', zorder=100)   \n",
    "                        plt.plot(test_t-2,slip_LNV,label = 'Linear Viscous Flow', color = colors[0], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_PLV,label='Power-law Viscous Flow', color = colors[1], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_VSF,label = 'Velocity Strengthening Friction\\n - steady state', color = colors[2], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_VSF_aSS,label = 'R+S - Stress >> Steady State', color = colors[3], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_VSF_bSS,label = 'R+S - Stress << Steady State', color = colors[4], linewidth=2, linestyle = '-')\n",
    "                        plt.plot(test_t-2,slip_RDF,label = 'RDF', color = colors[5], linewidth=2, linestyle = '-')\n",
    "                        plt.legend(fontsize=11)\n",
    "                        plt.xlabel('Time since start of event, hrs', fontsize=14)\n",
    "                        plt.ylabel('Slip, mm',fontsize=14)\n",
    "                        plt.xticks(fontsize=14)\n",
    "                        plt.yticks(fontsize=14)\n",
    "                        plt.title('{K}_{P}'.format(K = CREEPMETER[q], P = j ),fontsize=18)\n",
    "                        figure = plt.gcf()  # get current figure\n",
    "                        figure.set_size_inches(6,6)\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/Nelder-Mead/{k}_{u}_event_plot_Multi_phase_Nelder-Mead_01_MAY_23.pdf\".format(k=CREEPMETER[q],u=j),format='pdf')\n",
    "                        plt.savefig(\"/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/{k}/figures/Nelder-Mead/{k}_{u}_event_plot_Multi_phase_Nelder-Mead_01_MAY_23.png\".format(k=CREEPMETER[q],u=j),format='pdf')\n",
    "                        plt.close('all')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e364f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/XHR/fits/Nelder-Mead/0/XHR_0_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\n",
      "1\n",
      "/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/XHR/fits/Nelder-Mead/1/XHR_1_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\n",
      "2\n",
      "/home/earthquakes2/homes/Dan/Rheology/Single_rheology_28_APR_23/XHR/fits/Nelder-Mead/2/XHR_2_fit_dictionary_multi_phase_Nelder-Mead_01_MAY_23.txt\n",
      "Linear Viscous: 2\n",
      "Current date and time : \n",
      "2023-05-01 12:30:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/earthquakes1/software/Ubuntu/anaconda3/envs/dan2/lib/python3.10/site-packages/numba/core/ir_utils.py:2152: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'optimized_par' of function 'Linear_viscous'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"Rheology_fitting_toolkit.py\", line 27:\n",
      "@jit(nopython=True,error_model = 'numpy')\n",
      "def Linear_viscous(optimized_par,OBS_Time):\n",
      "^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/home/earthquakes1/software/Ubuntu/anaconda3/envs/dan2/lib/python3.10/site-packages/numba/core/ir_utils.py:2152: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'optimized_par' of function 'Linear_viscous'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"Rheology_fitting_toolkit.py\", line 27:\n",
      "@jit(nopython=True,error_model = 'numpy')\n",
      "def Linear_viscous(optimized_par,OBS_Time):\n",
      "^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:                         \u001b[38;5;66;03m# Create a multiprocessing Pool           \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_multi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/earthquakes1/software/Ubuntu/anaconda3/envs/dan2/lib/python3.10/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/earthquakes1/software/Ubuntu/anaconda3/envs/dan2/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/home/earthquakes1/software/Ubuntu/anaconda3/envs/dan2/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/earthquakes1/software/Ubuntu/anaconda3/envs/dan2/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/home/earthquakes1/software/Ubuntu/anaconda3/envs/dan2/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dictionary_all_events = {}\n",
    "if __name__ == '__main__':\n",
    "    with Pool(1) as pool:                         # Create a multiprocessing Pool           \n",
    "        pool.map(test_multi, dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ef8ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creep_event_dataframe_short(dataframe,df_auto):\n",
    "    dataframes={}\n",
    "    creep_index = np.array(df_auto.og_index)\n",
    "    for j in range(len(dataframe)):\n",
    "        boolarr = dataframe[j].Slip <= 0.8*max(dataframe[j].Slip)\n",
    "        SLIP = dataframe[j].Slip[boolarr]\n",
    "        TIME = dataframe[j].Time[boolarr]\n",
    "        VEL = dataframe[j].Velocity[boolarr]\n",
    "        ACC = dataframe[j].Acceleration[boolarr]\n",
    "        dataframes[creep_index[j]] = pd.DataFrame({'Time':TIME,'Slip':SLIP,'Velocity':VEL,'Acceleration':ACC})\n",
    "        dataframes[creep_index[j]].reset_index(inplace=True)\n",
    "    return dataframes, creep_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
